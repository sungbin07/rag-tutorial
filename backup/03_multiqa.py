#!/usr/bin/env python3
"""
Neo4j ê¸°ë°˜ Multi-hop QA ë°ì´í„° ìƒì„± ì‹œìŠ¤í…œ

ì´ ëª¨ë“ˆì€ êµ¬ì¶•ëœ Neo4j ê·¸ë˜í”„ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ í™œìš©í•˜ì—¬ 
multi-hop reasoningì´ í•„ìš”í•œ QA ë°ì´í„°ì…‹ì„ ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
1. Neo4j ê·¸ë˜í”„ì—ì„œ 2-3 hop ê²½ë¡œ íƒìƒ‰
2. ê²½ë¡œ ê¸°ë°˜ ìì—°ì–´ ì§ˆë¬¸ ìë™ ìƒì„±
3. Reasoning trace í¬í•¨ ë‹µë³€ ìƒì„±
4. ë‹¤ì–‘í•œ ì§ˆë¬¸ ìœ í˜• í…œí”Œë¦¿ ì ìš©
5. í’ˆì§ˆ í‰ê°€ ë° í•„í„°ë§
"""

import os
import json
import asyncio
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
import logging
from pathlib import Path

# LangChain imports
from dotenv import load_dotenv
from langchain_neo4j import Neo4jGraph, GraphCypherQAChain
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from langchain_core.prompts import ChatPromptTemplate

# Langfuse imports
from langfuse.langchain import CallbackHandler
from langfuse import Langfuse

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()


class QuestionType(Enum):
    """ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜"""
    ENTITY_RELATIONSHIP = "entity_relationship"  # ì—”í‹°í‹° ê°„ ê´€ê³„
    CAUSAL_INFERENCE = "causal_inference"        # ì¸ê³¼ ê´€ê³„ ì¶”ë¡ 
    TEMPORAL_SEQUENCE = "temporal_sequence"      # ì‹œê°„ì  ìˆœì„œ
    MULTI_HOP_FACT = "multi_hop_fact"           # ë‹¤ì¤‘ í™‰ ì‚¬ì‹¤ í™•ì¸
    COMPARATIVE = "comparative"                  # ë¹„êµ ë¶„ì„
    AGGREGATIVE = "aggregative"                 # ì§‘ê³„ ì •ë³´


class DifficultyLevel(Enum):
    """ë‚œì´ë„ ë¶„ë¥˜"""
    EASY = "easy"      # 2-hop, ì§ì ‘ì  ê´€ê³„
    MEDIUM = "medium"  # 2-3 hop, ì¤‘ê°„ ì¶”ë¡ 
    HARD = "hard"      # 3+ hop, ë³µì¡í•œ ì¶”ë¡ 


@dataclass
class GraphPath:
    """ê·¸ë˜í”„ ê²½ë¡œ ì •ë³´"""
    start_node: Dict[str, Any]
    end_node: Dict[str, Any]
    path_length: int
    relationships: List[Dict[str, Any]]
    path_description: str


@dataclass
class MultiHopQA:
    """Multi-hop QA ë°ì´í„° êµ¬ì¡°"""
    question: str
    answer: str
    reasoning_trace: List[str]
    question_type: QuestionType
    difficulty: DifficultyLevel
    confidence_score: float
    source_path: GraphPath
    metadata: Dict[str, Any]


class Neo4jMultiHopQAGenerator:
    """Neo4j ê¸°ë°˜ Multi-hop QA ìƒì„±ê¸° (Langfuse í†µí•©)"""
    
    def __init__(self, enable_langfuse: bool = True):
        """ì´ˆê¸°í™” ë° ì—°ê²° ì„¤ì •"""
        self.neo4j_uri = os.getenv("NEO4J_URI")
        self.neo4j_username = os.getenv("NEO4J_USERNAME") 
        self.neo4j_password = os.getenv("NEO4J_PASSWORD")
        
        if not all([self.neo4j_uri, self.neo4j_username, self.neo4j_password]):
            raise ValueError("Neo4j ì—°ê²° ì •ë³´ê°€ í™˜ê²½ë³€ìˆ˜ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # Neo4j ì—°ê²°
        self.graph = Neo4jGraph(
            url=self.neo4j_uri,
            username=self.neo4j_username,
            password=self.neo4j_password
        )
        
        # Langfuse ì„¤ì •
        self.enable_langfuse = enable_langfuse
        if enable_langfuse:
            try:
                self.langfuse_handler = CallbackHandler()
                logger.info("Langfuse ì—°ë™ í™œì„±í™”")
            except Exception as e:
                logger.warning(f"Langfuse ì—°ë™ ì‹¤íŒ¨, ë¹„í™œì„±í™”ë¨: {e}")
                self.enable_langfuse = False
                self.langfuse_handler = None
        else:
            self.langfuse_handler = None
        
        # LLM ì„¤ì •
        self.llm = ChatOpenAI(
            model="gpt-4o-mini", 
            temperature=0.3
        )
        
        # Cypher QA Chain ì„¤ì •
        self.cypher_chain = GraphCypherQAChain.from_llm(
            llm=self.llm,
            graph=self.graph,
            allow_dangerous_requests=True,
            verbose=False
        )
        
        logger.info("Neo4j Multi-hop QA Generator ì´ˆê¸°í™” ì™„ë£Œ")

    def get_graph_schema(self) -> str:
        """ê·¸ë˜í”„ ìŠ¤í‚¤ë§ˆ ì •ë³´ ì¡°íšŒ"""
        try:
            self.graph.refresh_schema()
            return self.graph.schema
        except Exception as e:
            logger.error(f"ìŠ¤í‚¤ë§ˆ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return ""

    def discover_multihop_paths(self, max_paths: int = 50) -> List[GraphPath]:
        """Multi-hop ê²½ë¡œ íƒìƒ‰"""
        logger.info("Multi-hop ê²½ë¡œ íƒìƒ‰ ì‹œì‘...")
        
        # ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡°ì— ë§ëŠ” 2-3 hop ê²½ë¡œ íƒìƒ‰ ì¿¼ë¦¬
        path_queries = [
            # 2-hop ê²½ë¡œ: Article -> Category -> Article
            """
            MATCH path = (start:Article)-[r1:BELONGS_TO]->(middle:Category)-[r2:BELONGS_TO]-(end:Article)
            WHERE start <> end
            AND start.title IS NOT NULL 
            AND end.title IS NOT NULL
            WITH path, start, middle, end, r1, r2
            RETURN 
                start, middle, end,
                type(r1) as rel1_type, type(r2) as rel2_type,
                length(path) as path_length,
                path
            ORDER BY rand()
            LIMIT $limit
            """,
            
            # 2-hop ê²½ë¡œ: Article -> Source -> Article  
            """
            MATCH path = (start:Article)-[r1:PUBLISHED]-(middle:Source)-[r2:PUBLISHED]-(end:Article)
            WHERE start <> end
            AND start.title IS NOT NULL 
            AND end.title IS NOT NULL
            WITH path, start, middle, end, r1, r2
            RETURN 
                start, middle, end,
                type(r1) as rel1_type, type(r2) as rel2_type,
                length(path) as path_length,
                path
            ORDER BY rand()
            LIMIT $limit
            """,
            
            # 3-hop ê²½ë¡œ: Article -> Category -> Article -> Category
            """
            MATCH path = (start:Article)-[r1:BELONGS_TO]->(n1:Category)-[r2:BELONGS_TO]-(n2:Article)-[r3:BELONGS_TO]->(end:Category)
            WHERE start <> n2 AND n1 <> end
            AND start.title IS NOT NULL 
            AND n2.title IS NOT NULL
            WITH path, start, n1, n2, end, r1, r2, r3
            RETURN 
                start, n1, n2, end,
                type(r1) as rel1_type, type(r2) as rel2_type, type(r3) as rel3_type,
                length(path) as path_length,
                path
            ORDER BY rand()
            LIMIT $limit
            """
        ]
        
        all_paths = []
        
        for query in path_queries:
            try:
                results = self.graph.query(query, {"limit": max_paths // 2})
                for result in results:
                    path = self._parse_path_result(result)
                    if path:
                        all_paths.append(path)
            except Exception as e:
                logger.error(f"ê²½ë¡œ íƒìƒ‰ ì¿¼ë¦¬ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
                continue
        
        logger.info(f"ì´ {len(all_paths)}ê°œì˜ multi-hop ê²½ë¡œ ë°œê²¬")
        return all_paths[:max_paths]

    def _get_node_label(self, node: Dict[str, Any]) -> str:
        """ë…¸ë“œì˜ ë¼ë²¨(íƒ€ì…) ì¶”ì¶œ"""
        # ì¿¼ë¦¬ì—ì„œ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •í•œ ë…¸ë“œ íƒ€ì… ê¸°ë°˜
        if isinstance(node, dict):
            # ë…¸ë“œ ë”•ì…”ë„ˆë¦¬ì—ì„œ ë¼ë²¨ ì •ë³´ë¥¼ ì°¾ê¸°
            if 'title' in node:  # Article ë…¸ë“œ
                return "Article"
            elif 'name' in node and len(node.get('name', '')) < 20:  # Category, Source ë“±
                return "Category" if node.get('name') in ['ì¼ë°˜', 'ê²½ì œ', 'ì‚¬íšŒ', 'êµ­ì œ', 'ìŠ¤í¬ì¸ ', 'IT', 'ì •ì¹˜', 'ë¬¸í™”', 'ì„¸ê³„'] else "Source"
            else:
                return "Node"
        return "Node"

    def _get_node_display_name(self, node: Dict[str, Any]) -> str:
        """ë…¸ë“œì˜ í‘œì‹œìš© ì´ë¦„ ì¶”ì¶œ"""
        if isinstance(node, dict):
            # Article ë…¸ë“œì˜ ê²½ìš° title ì‚¬ìš© (ì²« 50ìë§Œ)
            if 'title' in node:
                title = node['title']
                return title[:50] + "..." if len(title) > 50 else title
            # Category, Source ë“±ì˜ ê²½ìš° name ì‚¬ìš©
            elif 'name' in node:
                return node['name']
            # ê¸°íƒ€ ì‹ë³„ ê°€ëŠ¥í•œ ì†ì„±ë“¤
            elif 'content' in node:
                content = node['content']
                return content[:30] + "..." if len(content) > 30 else content
            elif 'id' in node:
                return f"ID:{node['id']}"
            else:
                return "Unknown"
        return str(node)[:50]

    def _parse_path_result(self, result: Dict[str, Any]) -> Optional[GraphPath]:
        """ê²½ë¡œ ê²°ê³¼ íŒŒì‹±"""
        try:
            path_length = result.get('path_length', 0)
            
            if path_length == 2:
                start_node = result['start']
                end_node = result['end']
                relationships = [
                    {'type': result['rel1_type'], 'direction': '->'},
                    {'type': result['rel2_type'], 'direction': '->'}
                ]
            elif path_length == 3:
                start_node = result['start']
                end_node = result['end']
                relationships = [
                    {'type': result['rel1_type'], 'direction': '->'},
                    {'type': result['rel2_type'], 'direction': '->'},
                    {'type': result['rel3_type'], 'direction': '->'}
                ]
            else:
                return None
            
            # ê²½ë¡œ ì„¤ëª… ìƒì„± - ë…¸ë“œ íƒ€ì… ì¶”ì¶œ
            start_label = self._get_node_label(start_node)
            end_label = self._get_node_label(end_node)
            
            # ë…¸ë“œë³„ë¡œ ì ì ˆí•œ ì†ì„± ì„ íƒ
            start_name = self._get_node_display_name(start_node)
            end_name = self._get_node_display_name(end_node)
            
            path_description = f"{start_label}({start_name})"
            for rel in relationships:
                path_description += f" -{rel['type']}-> "
            path_description += f"{end_label}({end_name})"
            
            return GraphPath(
                start_node=dict(start_node),
                end_node=dict(end_node),
                path_length=path_length,
                relationships=relationships,
                path_description=path_description
            )
            
        except Exception as e:
            logger.error(f"ê²½ë¡œ íŒŒì‹± ì˜¤ë¥˜: {e}")
            return None

    def generate_question_from_path(self, path: GraphPath) -> Optional[MultiHopQA]:
        """ê²½ë¡œ ê¸°ë°˜ ì§ˆë¬¸ ìƒì„± (Langfuse ì¶”ì  í¬í•¨)"""
        
        # ì§ˆë¬¸ ìƒì„± í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        question_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ì§€ì‹ ê·¸ë˜í”„ ê²½ë¡œë¥¼ ë¶„ì„í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì£¼ì–´ì§„ ê·¸ë˜í”„ ê²½ë¡œë¥¼ ë°”íƒ•ìœ¼ë¡œ multi-hop reasoningì´ í•„ìš”í•œ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸ ìƒì„± ê°€ì´ë“œë¼ì¸:
1. ìì—°ìŠ¤ëŸ½ê³  ëª…í™•í•œ í•œêµ­ì–´ ì§ˆë¬¸
2. ì‹œì‘ ë…¸ë“œì—ì„œ ë ë…¸ë“œê¹Œì§€ì˜ ì—°ê²° ê´€ê³„ë¥¼ íƒìƒ‰í•˜ëŠ” ì§ˆë¬¸
3. ë‹¨ìˆœí•œ ì‚¬ì‹¤ í™•ì¸ì´ ì•„ë‹Œ ì¶”ë¡ ì´ í•„ìš”í•œ ì§ˆë¬¸
4. ì‹¤ì œ ì‚¬ìš©ìê°€ ë¬¼ì–´ë³¼ ë²•í•œ ì‹¤ìš©ì ì¸ ì§ˆë¬¸

ì‘ë‹µ í˜•ì‹:
{{
    "question": "ìƒì„±ëœ ì§ˆë¬¸",
    "question_type": "entity_relationship|causal_inference|temporal_sequence|multi_hop_fact|comparative|aggregative",
    "difficulty": "easy|medium|hard",
    "reasoning_strategy": "ì´ ì§ˆë¬¸ì„ ë‹µí•˜ê¸° ìœ„í•œ ì¶”ë¡  ì „ëµ ì„¤ëª…"
}}"""),
            ("human", """ê·¸ë˜í”„ ê²½ë¡œ ì •ë³´:
- ì‹œì‘ ë…¸ë“œ: {start_node}
- ë ë…¸ë“œ: {end_node}  
- ê²½ë¡œ ê¸¸ì´: {path_length}
- ê´€ê³„ë“¤: {relationships}
- ê²½ë¡œ ì„¤ëª…: {path_description}

ì´ ê²½ë¡œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.""")
        ])
        
        try:
            # Langfuse config ì„¤ì •
            config = {"callbacks": [self.langfuse_handler]} if self.enable_langfuse else {}
            
            # ì§ˆë¬¸ ìƒì„±
            response = self.llm.invoke(
                question_prompt.format_messages(
                    start_node=path.start_node,
                    end_node=path.end_node,
                    path_length=path.path_length,
                    relationships=path.relationships,
                    path_description=path.path_description
                ),
                config=config
            )
            
            # JSON íŒŒì‹±
            try:
                question_data = json.loads(response.content)
            except json.JSONDecodeError:
                # JSON í˜•ì‹ì´ ì•„ë‹Œ ê²½ìš° ë‹¨ìˆœ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬
                question_data = {
                    "question": response.content,
                    "question_type": "multi_hop_fact",
                    "difficulty": "medium",
                    "reasoning_strategy": "ê·¸ë˜í”„ ê²½ë¡œ ê¸°ë°˜ ì¶”ë¡ "
                }
            
            # ë‹µë³€ ë° reasoning trace ìƒì„±
            answer_data = self._generate_answer_with_trace(
                question_data["question"], 
                path
            )
            
            # ìµœì¢… QA ê°ì²´ ìƒì„±
            qa = MultiHopQA(
                question=question_data["question"],
                answer=answer_data["answer"],
                reasoning_trace=answer_data["reasoning_trace"],
                question_type=QuestionType(question_data["question_type"]),
                difficulty=DifficultyLevel(question_data["difficulty"]),
                confidence_score=answer_data["confidence"],
                source_path=path,
                metadata={
                    "reasoning_strategy": question_data.get("reasoning_strategy", ""),
                    "generation_timestamp": datetime.now().isoformat()
                }
            )
            
            return qa
            
        except Exception as e:
            logger.error(f"ì§ˆë¬¸ ìƒì„± ì˜¤ë¥˜: {e}")
            return None

    def _generate_answer_with_trace(self, question: str, path: GraphPath) -> Dict[str, Any]:
        """ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ê³¼ reasoning trace ìƒì„± (Langfuse ì¶”ì  í¬í•¨)"""
        
        # Reasoning trace ìƒì„± í”„ë¡¬í”„íŠ¸
        trace_prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ê·¸ë˜í”„ ê¸°ë°˜ ì¶”ë¡  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì§ˆë¬¸ê³¼ ê·¸ë˜í”„ ê²½ë¡œë¥¼ ë°”íƒ•ìœ¼ë¡œ 
ë‹¨ê³„ë³„ ì¶”ë¡  ê³¼ì •ê³¼ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

ì‘ë‹µ í˜•ì‹:
{{
    "reasoning_trace": [
        "1ë‹¨ê³„: ì²« ë²ˆì§¸ ì¶”ë¡  ë‹¨ê³„",
        "2ë‹¨ê³„: ë‘ ë²ˆì§¸ ì¶”ë¡  ë‹¨ê³„", 
        "3ë‹¨ê³„: ìµœì¢… ê²°ë¡  ë„ì¶œ"
    ],
    "answer": "ìµœì¢… ë‹µë³€",
    "confidence": 0.85
}}"""),
            ("human", """ì§ˆë¬¸: {question}

ê·¸ë˜í”„ ê²½ë¡œ ì •ë³´:
- ê²½ë¡œ ì„¤ëª…: {path_description}
- ì‹œì‘ ë…¸ë“œ: {start_node}
- ë ë…¸ë“œ: {end_node}
- ê´€ê³„ ì²´ì¸: {relationships}

ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¨ê³„ë³„ ì¶”ë¡  ê³¼ì •ê³¼ ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”.""")
        ])
        
        try:
            # Langfuse config ì„¤ì •
            config = {"callbacks": [self.langfuse_handler]} if self.enable_langfuse else {}
            
            response = self.llm.invoke(
                trace_prompt.format_messages(
                    question=question,
                    path_description=path.path_description,
                    start_node=path.start_node,
                    end_node=path.end_node,
                    relationships=" -> ".join([rel['type'] for rel in path.relationships])
                ),
                config=config
            )
            
            try:
                result = json.loads(response.content)
                return result
                
            except json.JSONDecodeError:
                # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ êµ¬ì¡° ë°˜í™˜
                fallback_result = {
                    "reasoning_trace": [
                        f"1ë‹¨ê³„: {self._get_node_display_name(path.start_node)}ì—ì„œ ì‹œì‘",
                        f"2ë‹¨ê³„: {' -> '.join([rel['type'] for rel in path.relationships])} ê´€ê³„ë¥¼ ë”°ë¼ ì´ë™",
                        f"3ë‹¨ê³„: {self._get_node_display_name(path.end_node)}ì— ë„ë‹¬í•˜ì—¬ ì •ë³´ í™•ì¸"
                    ],
                    "answer": response.content,
                    "confidence": 0.7
                }
                return fallback_result
                
        except Exception as e:
            logger.error(f"ì¶”ë¡  trace ìƒì„± ì˜¤ë¥˜: {e}")
            
            error_result = {
                "reasoning_trace": ["ì¶”ë¡  ê³¼ì • ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ"],
                "answer": "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "confidence": 0.0
            }
            return error_result

    def validate_qa_quality(self, qa: MultiHopQA) -> bool:
        """QA í’ˆì§ˆ ê²€ì¦"""
        
        # ê¸°ë³¸ ê²€ì¦
        if not qa.question or not qa.answer:
            return False
            
        if len(qa.question) < 10 or len(qa.answer) < 10:
            return False
            
        if qa.confidence_score < 0.5:
            return False
            
        # ì¶”ê°€ í’ˆì§ˆ ê²€ì¦ ë¡œì§
        if "ì˜¤ë¥˜" in qa.answer or "ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in qa.answer:
            return False
            
        return True

    async def generate_multihop_dataset(
        self, 
        target_size: int = 100,
        min_confidence: float = 0.6
    ) -> List[MultiHopQA]:
        """Multi-hop QA ë°ì´í„°ì…‹ ìƒì„± (Langfuse ì¶”ì  í¬í•¨)"""
        
        logger.info(f"Multi-hop QA ë°ì´í„°ì…‹ ìƒì„± ì‹œì‘ (ëª©í‘œ: {target_size}ê°œ)")
        
        # 1. ê·¸ë˜í”„ ê²½ë¡œ íƒìƒ‰
        paths = self.discover_multihop_paths(max_paths=target_size * 2)
        
        if not paths:
            logger.warning("íƒìƒ‰ëœ ê·¸ë˜í”„ ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        # 2. ë³‘ë ¬ë¡œ QA ìƒì„±
        qa_tasks = []
        for path in paths:
            qa_tasks.append(self._generate_qa_async(path))
        
        # 3. ë¹„ë™ê¸° ì‹¤í–‰
        qa_results = await asyncio.gather(*qa_tasks, return_exceptions=True)
        
        # 4. ê²°ê³¼ ìˆ˜ì§‘ ë° í•„í„°ë§
        valid_qas = []
        for result in qa_results:
            if isinstance(result, MultiHopQA) and self.validate_qa_quality(result):
                if result.confidence_score >= min_confidence:
                    valid_qas.append(result)
        
        # 5. ë‹¤ì–‘ì„± í™•ë³´ë¥¼ ìœ„í•œ ì„ ë³„
        final_qas = self._diversify_qa_selection(valid_qas, target_size)
        
        logger.info(f"ìµœì¢… ìƒì„±ëœ QA ê°œìˆ˜: {len(final_qas)}")
        return final_qas

    async def _generate_qa_async(self, path: GraphPath) -> Optional[MultiHopQA]:
        """ë¹„ë™ê¸° QA ìƒì„±"""
        try:
            return self.generate_question_from_path(path)
        except Exception as e:
            logger.error(f"ë¹„ë™ê¸° QA ìƒì„± ì˜¤ë¥˜: {e}")
            return None

    def _diversify_qa_selection(self, qas: List[MultiHopQA], target_size: int) -> List[MultiHopQA]:
        """QA ë‹¤ì–‘ì„± í™•ë³´"""
        if len(qas) <= target_size:
            return qas
        
        # ì§ˆë¬¸ ìœ í˜•ë³„ ë¶„ë¥˜
        type_groups = {}
        for qa in qas:
            qtype = qa.question_type.value
            if qtype not in type_groups:
                type_groups[qtype] = []
            type_groups[qtype].append(qa)
        
        # ê° ìœ í˜•ì—ì„œ ê· ë“±í•˜ê²Œ ì„ íƒ
        selected = []
        per_type = target_size // len(type_groups)
        
        for qtype, group in type_groups.items():
            # ì‹ ë¢°ë„ ê¸°ì¤€ ì •ë ¬
            group.sort(key=lambda x: x.confidence_score, reverse=True)
            selected.extend(group[:per_type])
        
        # ë¶€ì¡±í•œ ë§Œí¼ ì¶”ê°€ ì„ íƒ
        remaining = target_size - len(selected)
        if remaining > 0:
            all_remaining = [qa for qa in qas if qa not in selected]
            all_remaining.sort(key=lambda x: x.confidence_score, reverse=True)
            selected.extend(all_remaining[:remaining])
        
        return selected[:target_size]

    def save_dataset(self, qas: List[MultiHopQA], output_path: str) -> None:
        """ë°ì´í„°ì…‹ ì €ì¥"""
        
        # QA ê°ì²´ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
        qa_dicts = []
        for qa in qas:
            qa_dict = asdict(qa)
            # Enum ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            qa_dict['question_type'] = qa.question_type.value
            qa_dict['difficulty'] = qa.difficulty.value
            
            # source_path ì•ˆì˜ DateTime ë“± ë³µì¡í•œ ê°ì²´ë“¤ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
            if 'source_path' in qa_dict:
                path_dict = qa_dict['source_path']
                # ë”•ì…”ë„ˆë¦¬ ë‚´ì˜ ëª¨ë“  ê°’ì„ ë¬¸ìì—´ë¡œ ë³€í™˜ (JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ë„ë¡)
                for key, value in path_dict.items():
                    if not isinstance(value, (str, int, float, bool, list, dict, type(None))):
                        path_dict[key] = str(value)
                        
                # ë…¸ë“œ ì •ë³´ë„ ë¬¸ìì—´ë¡œ ë³€í™˜
                if 'start_node' in path_dict and isinstance(path_dict['start_node'], dict):
                    for k, v in path_dict['start_node'].items():
                        if not isinstance(v, (str, int, float, bool, list, dict, type(None))):
                            path_dict['start_node'][k] = str(v)
                            
                if 'end_node' in path_dict and isinstance(path_dict['end_node'], dict):
                    for k, v in path_dict['end_node'].items():
                        if not isinstance(v, (str, int, float, bool, list, dict, type(None))):
                            path_dict['end_node'][k] = str(v)
            
            qa_dicts.append(qa_dict)
        
        output_data = {
            "metadata": {
                "total_count": len(qas),
                "generation_timestamp": datetime.now().isoformat(),
                "generator_version": "1.0.0",
                "source": "neo4j_multihop_generator"
            },
            "statistics": self._calculate_statistics(qas),
            "qa_pairs": qa_dicts
        }
        
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ë°ì´í„°ì…‹ ì €ì¥ ì™„ë£Œ: {output_path}")

    def _calculate_statistics(self, qas: List[MultiHopQA]) -> Dict[str, Any]:
        """ë°ì´í„°ì…‹ í†µê³„ ê³„ì‚°"""
        if not qas:
            return {}
        
        type_counts = {}
        difficulty_counts = {}
        
        for qa in qas:
            # ì§ˆë¬¸ ìœ í˜• í†µê³„
            qtype = qa.question_type.value
            type_counts[qtype] = type_counts.get(qtype, 0) + 1
            
            # ë‚œì´ë„ í†µê³„
            difficulty = qa.difficulty.value
            difficulty_counts[difficulty] = difficulty_counts.get(difficulty, 0) + 1
        
        return {
            "question_type_distribution": type_counts,
            "difficulty_distribution": difficulty_counts,
            "average_confidence": sum(qa.confidence_score for qa in qas) / len(qas),
            "average_path_length": sum(qa.source_path.path_length for qa in qas) / len(qas),
            "reasoning_trace_avg_length": sum(len(qa.reasoning_trace) for qa in qas) / len(qas)
        }

    def generate_sample_queries(self) -> List[str]:
        """ìƒ˜í”Œ ì§ˆì˜ ìƒì„± (ë””ë²„ê¹…/í…ŒìŠ¤íŠ¸ìš©)"""
        
        sample_queries = [
            # ê¸°ë³¸ ì—°ê²°ì„± í™•ì¸
            "MATCH (n) RETURN labels(n) as node_types, count(n) as count ORDER BY count DESC LIMIT 10",
            
            # ê´€ê³„ ìœ í˜• í™•ì¸  
            "MATCH ()-[r]->() RETURN type(r) as rel_type, count(r) as count ORDER BY count DESC LIMIT 10",
            
            # 2-hop ê²½ë¡œ ìƒ˜í”Œ
            "MATCH (a)-[r1]->(b)-[r2]->(c) RETURN a.name, type(r1), b.name, type(r2), c.name LIMIT 5",
            
            # í—ˆë¸Œ ë…¸ë“œ í™•ì¸
            "MATCH (n) WITH n, size((n)--()) as degree WHERE degree > 3 RETURN n.name, labels(n), degree ORDER BY degree DESC LIMIT 10"
        ]
        
        return sample_queries

    def test_connection_and_schema(self) -> Dict[str, Any]:
        """ì—°ê²° ë° ìŠ¤í‚¤ë§ˆ í…ŒìŠ¤íŠ¸"""
        try:
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            result = self.graph.query("MATCH (n) RETURN count(n) as total_nodes LIMIT 1")
            total_nodes = result[0]['total_nodes'] if result else 0
            
            # ìŠ¤í‚¤ë§ˆ ì •ë³´
            schema = self.get_graph_schema()
            
            # ìƒ˜í”Œ ì¿¼ë¦¬ ì‹¤í–‰
            sample_results = {}
            for i, query in enumerate(self.generate_sample_queries()):
                try:
                    sample_results[f"query_{i+1}"] = self.graph.query(query)
                except Exception as e:
                    sample_results[f"query_{i+1}"] = f"Error: {str(e)}"
            
            return {
                "connection_status": "success",
                "total_nodes": total_nodes,
                "schema": schema,
                "sample_query_results": sample_results
            }
            
        except Exception as e:
            return {
                "connection_status": "failed",
                "error": str(e)
            }


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (Langfuse í†µí•©)"""
    
    print("ğŸš€ Neo4j Multi-hop QA ë°ì´í„° ìƒì„± ì‹œìŠ¤í…œ ì‹œì‘ (Langfuse í†µí•©)")
    print("=" * 70)
    
    try:
        # 1. ìƒì„±ê¸° ì´ˆê¸°í™”
        generator = Neo4jMultiHopQAGenerator(enable_langfuse=True)
        
        # Langfuse ìƒíƒœ í™•ì¸
        if generator.enable_langfuse:
            print("âœ… Langfuse ì—°ë™ í™œì„±í™”ë¨")
            print("ğŸ“Š Langfuse ëŒ€ì‹œë³´ë“œì—ì„œ ì‹¤ì‹œê°„ ì¶”ì ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤")
        else:
            print("âš ï¸ Langfuse ì—°ë™ ë¹„í™œì„±í™”ë¨")
        
        # 2. ì—°ê²° ë° ìŠ¤í‚¤ë§ˆ í…ŒìŠ¤íŠ¸
        print("\nğŸ“Š Neo4j ì—°ê²° ë° ìŠ¤í‚¤ë§ˆ í…ŒìŠ¤íŠ¸...")
        test_result = generator.test_connection_and_schema()
        
        if test_result["connection_status"] == "failed":
            print(f"âŒ Neo4j ì—°ê²° ì‹¤íŒ¨: {test_result['error']}")
            return
        
        print(f"âœ… Neo4j ì—°ê²° ì„±ê³µ (ì´ ë…¸ë“œ ìˆ˜: {test_result['total_nodes']})")
        print(f"ğŸ“‹ ìŠ¤í‚¤ë§ˆ ì •ë³´: {test_result['schema'][:200]}...")
        
        # 3. Multi-hop QA ìƒì„±
        print("\nğŸ” Multi-hop QA ë°ì´í„° ìƒì„± ì¤‘...")
        print("  ğŸ“ˆ Langfuseì—ì„œ ì‹¤ì‹œê°„ ì¶”ì  ê°€ëŠ¥í•©ë‹ˆë‹¤...")
        
        qa_dataset = await generator.generate_multihop_dataset(
            target_size=20,      # ìƒì„±í•  QA ê°œìˆ˜ (í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì¤„ì„)
            min_confidence=0.6   # ìµœì†Œ ì‹ ë¢°ë„
        )
        
        if not qa_dataset:
            print("âŒ QA ë°ì´í„° ìƒì„± ì‹¤íŒ¨")
            return
        
        # 4. ê²°ê³¼ ì¶œë ¥
        print(f"\nâœ… {len(qa_dataset)}ê°œì˜ Multi-hop QA ìƒì„± ì™„ë£Œ!")
        
        # ìƒ˜í”Œ QA ì¶œë ¥ (Langfuse trace ID í¬í•¨)
        print("\nğŸ“ ìƒì„±ëœ QA ìƒ˜í”Œ:")
        for i, qa in enumerate(qa_dataset[:3], 1):
            print(f"\n--- QA {i} ---")
            print(f"ì§ˆë¬¸: {qa.question}")
            print(f"ë‹µë³€: {qa.answer}")
            print(f"ìœ í˜•: {qa.question_type.value}")
            print(f"ë‚œì´ë„: {qa.difficulty.value}")
            print(f"ì‹ ë¢°ë„: {qa.confidence_score:.2f}")
            print(f"ì¶”ë¡  ë‹¨ê³„: {len(qa.reasoning_trace)}ë‹¨ê³„")
            for j, step in enumerate(qa.reasoning_trace, 1):
                print(f"  {j}. {step}")
            print(f"ê·¸ë˜í”„ ê²½ë¡œ: {qa.source_path.path_description}")
            
            # Langfuse ì¶”ì  ìƒíƒœ í‘œì‹œ
            if generator.enable_langfuse:
                print("ğŸ”— Langfuseì—ì„œ ì¶”ì ë¨")
        
        # 5. ë°ì´í„°ì…‹ ì €ì¥
        output_path = f"data/multihop_qa_dataset_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        generator.save_dataset(qa_dataset, output_path)
        
        # 6. í†µê³„ ì¶œë ¥
        stats = generator._calculate_statistics(qa_dataset)
        print(f"\nğŸ“ˆ ë°ì´í„°ì…‹ í†µê³„:")
        print(f"  - í‰ê·  ì‹ ë¢°ë„: {stats['average_confidence']:.2f}")
        print(f"  - í‰ê·  ê²½ë¡œ ê¸¸ì´: {stats['average_path_length']:.1f}")
        print(f"  - í‰ê·  ì¶”ë¡  ë‹¨ê³„: {stats['reasoning_trace_avg_length']:.1f}")
        print(f"  - ì§ˆë¬¸ ìœ í˜• ë¶„í¬: {stats['question_type_distribution']}")
        print(f"  - ë‚œì´ë„ ë¶„í¬: {stats['difficulty_distribution']}")
        
        print(f"\nğŸ’¾ ë°ì´í„°ì…‹ ì €ì¥ ì™„ë£Œ: {output_path}")
        
        # 7. Langfuse ì •ë³´ ì¶œë ¥
        if generator.enable_langfuse:
            print(f"\nğŸ” Langfuse ì¶”ì  ì •ë³´:")
            print(f"  - ëª¨ë“  QA ìƒì„± ê³¼ì •ì´ Langfuseì— ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤")
            print(f"  - ëŒ€ì‹œë³´ë“œì—ì„œ ì„±ëŠ¥ ì§€í‘œì™€ ì¶”ë¡  ê³¼ì •ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        
        print("\nğŸ‰ Multi-hop QA ë°ì´í„° ìƒì„± ì™„ë£Œ!")
        
    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    asyncio.run(main())
